library(devtools)
library(table1)
library(dplyr)
library(naniar)
library(ggplot2)
library("ggthemes")
library(tidyverse)
library(ggpubr)
library(Hmisc)
library(naniar)
library(finalfit)
library(visdat)
library(mice)
## ----------------------------
## Install packages needed:  (uncomment as required)
# if(!require(table1)){install.packages("table1")}
# if(!require(dplyr)){install.packages('dplyr')}
# if(!require(naniar)){install.packages(('naniar'))}
# if(!require(ggplot2)){install.packages("ggplot2")}
# if(!require(ggthemes)){install.packages("ggthemes")}
# if(!require(tidyverse)){install.packages('tidyverse')}
# if(!require(mvnmle)){install.packages('finalfit')}
# if(!require(ggpubr)){install.packages("ggpubr")}
# if(!require(Gally)){install.packages("Gally")}
# if(!require(visdat)){install.packages("visdat")}
# if(!require(mice)){install.packages("mice")}
#### ---------------------------
#Set output directorypaths
outdir_figures='/Users/jutzca/Documents/Github/SCI_Neurological_Recovery/EMSCI/Figures'
outdir_tables='/Users/jutzca/Documents/Github/SCI_Neurological_Recovery/EMSCI/Tables'
#### -------------------------------------------------------------------------- CODE START ------------------------------------------------------------------------------------------------####
#-------------------------Data wrangling-----
#load original dataset
emsci<- read.csv("/Volumes/jutzelec$/8_Projects/1_Ongoing/9_EMSCI_epidemiological_shift/2_Data/emsci_data_2020.csv", sep = ',', header = T,  na.strings=c("","NA"))
#Only include subject with information on sex, valid age at injury, traumatic or ischemic cause of injury, and level of injury either cervical, thoracic, or lumbar; as well as AIS score A, B, C, or D
emsci <- subset(emsci, (AgeAtDOI > 8) & (Sex=='f' | Sex=='m') & ###Age at DOI and Sex
(Cause=="ischemic" | Cause=="traumatic" | Cause=="haemorragic" |Cause=="disc herniation") &
(NLI_level == 'cervical' | NLI_level == 'thoracic'| NLI_level == 'lumbar')&   ## Neurological level
(AIS=="A"| AIS=="B"| AIS=="C"| AIS=="D")) #AIS Grades
#Visualize missingness in the masterfile
##https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html
#Subset Data
emsci_subset <- emsci[,c(2,3,4,5,8,9,11,12,16,18,20,23,26,29,32,35,36,178,179,186,188,190,192,196,216)]
#Subset data to most important variables
#E.g., total scores of SCIM serve as proxy for the subscores. The rationale for that arises from the fact, that the total scores can not be
#calculated if the subscores have not been assessed. Same applies for LT, PP, LEMS, UEMS, TMS
emsci_subset_newnames<-emsci_subset %>%
rename(
'Neurological level of Injury' = NLI,
#"Time up and go" = TUG,
"10m walking test" =X10m,
'6min walking test' = X6min,
'Plegia' =plegia,
"Total pin prick" =TPP,
"Total light touch" = TLT,
"Lower extremity motor score" = LEMS,
"Upper extremity motor score" = UEMS,
"Total motor score" = TMS,
"Age at Injury" = AgeAtDOI,
"Year of Injury" = YEARDOI,
"PID" = Patientennummer,
'Combined Total Score SCIM2 and 3'= SCIM23_TotalScore,
'SCIM2 Total Score' = SCIM2_TotalScore,
'SCIM3 Total Score' = SCIM3_TotalScore,
'Walking Index for Spinal Cord Injury' = WISCI,
'Voluntary anal contraction' = VAC,
'Deep anal pressure' =DAP)
#Initial visualization of missing data
vis_miss(emsci_subset_newnames, sort_miss = T)
#Visualization of patter in missing data
pattern_missing_data <- gg_miss_upset(emsci_subset_newnames,  nsets = 50,
nintersects = 20)
pattern_missing_data
#Visualize the missing data by exam stage
missing_data_examstage<-gg_miss_var(emsci_subset_newnames, facet=ExamStage, show_pct = TRUE)+
scale_y_continuous(labels = abs, limits = c(0, 100), breaks = seq(0, 100, 10))+
geom_hline(yintercept = 0) +
theme_economist(horizontal = FALSE) +
scale_fill_economist() +
labs(fill = "", x = "", y = "% missing values")+ #ggtitle("% missing values, by exam stage and variable")+
theme(axis.title = element_text(size = 10, face = 'bold'),
axis.text = element_text(size = 10),
plot.title = element_text(hjust = 0.5, size=10),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)),
strip.text = element_text(size =10)
)
missing_data_examstage
ggsave(
"missing_data_examstage.emsci.pdf",
plot = missing_data_examstage,
device = 'pdf',
path = outdir_figures,    ###Set path to save figures
scale = 1,
width = 10,
height = 9,
units = "in",
dpi = 300
)
dev.off()
#Visualize the missing data by ais grades
missing_data_ais<-gg_miss_var(emsci_subset_newnames, facet=AIS, show_pct = TRUE)+
scale_y_continuous(labels = abs, limits = c(0, 100), breaks = seq(0, 100, 10))+
geom_hline(yintercept = 0) +
theme_economist(horizontal = FALSE) +
scale_fill_economist() +
labs(fill = "", x = "", y = "% missing values")+ #ggtitle("% missing values, by exam stage and variable")+
theme(axis.title = element_text(size = 10, face = 'bold'),
axis.text = element_text(size = 10),
plot.title = element_text(hjust = 0.5, size=10),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)),
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)),
strip.text = element_text(size =10)
)
missing_data_ais
ggsave(
"missing_data_ais_emsci.pdf",
plot = missing_data_ais,
device = 'pdf',
path = outdir_figures,    ###Set path to save figures
scale = 1,
width = 9,
height = 10,
units = "in",
dpi = 300
)
dev.off()
#### -------------------------------------------------------------------------- CODE END ------------------------------------------------------------------------------------------------####
#Visualization of patter in missing data
pattern_missing_data <- gg_miss_upset(emsci_subset_newnames,  nsets = 50,
nintersects = 20)
pattern_missing_data
ggsave(
"missing_data_pattern.emsci.pdf",
plot = pattern_missing_data.emsci,
device = 'pdf',
path = outdir_figures,    ###Set path to save figures
scale = 1,
width = 10,
height = 9,
units = "in",
dpi = 300
)
dev.off()
#Visualization of patter in missing data
pattern_missing_data.emsci <- gg_miss_upset(emsci_subset_newnames,  nsets = 50,
nintersects = 20)
pattern_missing_data.emsci
ggsave(
"missing_data_pattern.emsci.pdf",
plot = pattern_missing_data.emsci,
device = 'pdf',
path = outdir_figures,    ###Set path to save figures
scale = 1,
width = 10,
height = 9,
units = "in",
dpi = 300
)
dev.off()
pattern_missing_data.emsci
#Load original data
drug <- read.csv("/Users/localadmin/Documents/5_R/Drug_addep/masterfile/catherine_drug_file_new.csv", header = T, sep = ',')
#Load original data
drug <- read.csv("/Volumes/jutzelec$/8_Projects/1_Ongoing/3_Drugs/Drug_addep/masterfile/catherine_drug_file_new.csv", header = T, sep = ',')
##Add character c to ID
drug$newid<- sprintf('C%i', drug$newid)
drug <- drug[order(drug$generic_name),]
drug_split <- split(drug, drug$generic_name)
new_names <- as.character(unique(drug$generic_name))
for (i in 1:length(drug_split)) {
assign(new_names[i],  drug_split[[i]])
write.csv(drug_split[[i]], paste("/Users/localadmin/Documents/5_R/Drug_addep/data/",new_names[i],".csv"))
}
###Load data
setwd("/Users/localadmin/Documents/5_R/Drug_addep/data/")
library(ggplot2)
library(reshape2)
library(hablar)
library(dplyr)
library(data.table)
new_names <- as.character(unique(drug$generic_name))
for (i in 1:length(drug_split)) {
assign(new_names[i],  drug_split[[i]])
write.csv(drug_split[[i]], paste("/Volumes/jutzelec$/8_Projects/1_Ongoing/3_Drugs/Drug_addep/data/",new_names[i],".csv"))
}
## ---------------------------
##
## Script name: 1_COVID-19_survey
##
## Purpose of script: To analyze and visualize the data from the COVID-19 survey assessing how the COVID-10 pamdemic has impacted the physical activity in patients
##                    suffering from neurological diseases. A cross-sectional study
##
## Author: Dr. Catherine Jutzeler
##
## Date Created: 2020-12-3
##
## Copyright (c) Catherine Jutzeler, 2020
## Email: catherine.jutzeler@bsse.ethz.ch
##
## ---------------------------
##
## Data source: COVID-19 survey
##
## Notes: This analysis is for the publication Nightingale et al, 2021 published in XX. [add link here]
##
#### ---------------------------
## set working directory
setwd("/Users/jutzca/Documents/Github/COVID-19_Excercise_Neurological_Conditions/")
## ---------------------------
## load up the packages we will need:
library(table1)
## ----------------------------
## Install packages needed:  (uncomment as required)
#if(!require(dplyr)){install.packages("dplyr")}
#if(!require(tidyr)){install.packages("tidyr")}
#if(!require(tidyverse)){install.packages("tidyverse")}
#if(!require(hrbrthemes)){install.packages("hrbrthemes")}
#if(!require(formattable)){install.packages("formattable")}
#if(!require(viridis)){install.packages("viridis")}
#if(!require(ggplot2)){install.packages("ggplot2")}
#if(!require(ggpubr)){install.packages("ggpubr")}
#if(!require(naniar)){install.packages("naniar")}
#### ---------------------------
#Clear working space
rm(list = ls())
#### ---------------------------
#Set output directorypaths
outdir_figures='/Users/jutzca/Documents/Github/COVID-19_Excercise_Neurological_Conditions/Figures/'
outdir_tables='/Users/jutzca/Documents/Github/COVID-19_Excercise_Neurological_Conditions/Tables/'
#### -------------------------------------------------------------------------- CODE START ------------------------------------------------------------------------------------------------####
#load original data
covid19.survey.data <- read.csv("/Volumes/jutzelec$/8_Projects/1_Ongoing/19_COVID_Survey/covid19_data_survey.csv", header = T, sep = ',')
names(covid19.survey.data)
#----- Create Summary Table of Included Cohort -----
### Formatting of table: Customize levels, labels, and units of listed variables
# 1. Change class of variables
covid19.survey.data$GRSI <- as.factor(covid19.survey.data$GRSI )
# 2. Change order of levels of specific factors
covid19.survey.data$Situation <- factor(covid19.survey.data$Situation, levels = c("self-imposed isolation", "goverment-issued isolation",
"social distancing", "none", "other"))
covid19.survey.data$Mobility_Aid <- factor(covid19.survey.data$Mobility_Aidn, levels = c("manual wheelchair","powered wheelchair", "mobility scooter", "zimmer frame","walking sticks", "crutches",
"none", "other"))
# 3. Change names of levels of variables
levels(covid19.survey.data$Sex) <- c("Female", "Male", "Prefer not to disclose")
levels(covid19.survey.data$Ethnicity) <- c("Asian/Asian British", "Black/African/Caribbean/Black British", "Caucasian/White", "Mixed/multiple ethnic groups", 'Other')
levels(covid19.survey.data$Situation) <- c("Self-imposed isolation/shielded (considered at-risk)", "Isolation due to government legislation",
"Practising social distancing", "None of the above", "Other")
levels(covid19.survey.data$Condition) <- c("Cerebral Palsy", "Fibromyalgia, Chronic fatigue syndromee, CRPS" , "Muscular dystrophy, neuromuscular diseases",
"Multiple Sclerosis", "Parkinson's disease", "Spinal Cord Injury", "Stroke, ataxia's, other (spina bifida, dystonia)")
levels(covid19.survey.data$Mobility_Aid) <- c("Manual wheelchair","Power wheelchair", "Mobility scooter", "Zimmer frame","Walking sticks", "Crutches",
"None", "Other")
# 4. Relable variables
label(covid19.survey.data$Sex) <- "Sex, n (%)"
label(covid19.survey.data$Age) <- "Age"
label(covid19.survey.data$Mobility_Aid) <- "Mobility Aid, n (%)"
label(covid19.survey.data$GRSI) <- "Government Response Stringency Index, n (%)"
label(covid19.survey.data$Condition) <- 'Condition, n (%)'
label(covid19.survey.data$Ethnicity) <- 'Ethnicity, n (%)'
label(covid19.survey.data$Situation) <- 'Situation, n (%)'
# 5. Assign units to Age at Injury and Year of Injury
units(covid19.survey.data$Age) <- "years"
# 6. Print table
table1::table1(~ Sex+Age+Ethnicity+Condition+Situation+Mobility_Aid+GRSI , data = covid19.survey.data)
http://rnotr.com/likert/ggplot/barometer/likert-plots/
ggplot() + geom_bar(data=highs, aes(x = outcome, y=value, fill=col), position="stack", stat="identity") +
geom_bar(data=lows, aes(x = outcome, y=-value, fill=col), position="stack", stat="identity") +
geom_hline(yintercept = 0, color =c("white")) +
scale_fill_identity("Percent", labels = mylevels, breaks=legend.pal, guide="legend") +
theme_fivethirtyeight() +
coord_flip() +
labs(title=mytitle, y="",x="") +
theme(plot.title = element_text(size=14, hjust=0.5)) +
theme(axis.text.y = element_text(hjust=0)) +
theme(legend.position = "bottom") +
scale_y_continuous(breaks=seq(mymin,mymax,25), limits=c(mymin,mymax))
covid19.survey.data <- read.csv("/Volumes/jutzelec$/8_Projects/1_Ongoing/19_COVID_Survey/covid19_data_survey.csv", header = T, sep = ',')
names(covid19.survey.data)
#subset data to remove NA from the y variable
Anxiety_score_without_na <-subset(covid19.survey.data, (!is.na(Anxiety_SCORE)))
## ---------------------------
## load up the packages we will need:
library(partykit)
install.packages("partykit")
## ---------------------------
## load up the packages we will need:
library(partykit)
model1<-partykit::ctree(Anxiety_SCORE~Age+as.factor(Sex), data=Anxiety_score_without_na, na.action = na.pass)
plot(model1)
model2<-ctree(Anxiety_SCORE~Age+as.factor(Sex)+as.factor(Situation)+as.factor(Ethnicity)+as.factor(Condition)+Duration_Corrected+as.factor(Mobility_Aid)+PASIDP_SCORE, data=Anxiety_score_without_na, na.action = na.pass)
plot(model2)
library(plyr)
library(readr)
library(dplyr)
library(caret)
library(ggplot2)
library(repr)
install.packages("caret")
## ---------------------------
## load up the packages we will need:
library(partykit)
library(plyr)
library(readr)
library(dplyr)
library(caret)
library(ggplot2)
library(repr)
install.packages("repr")
dat <- read_csv("reg_data.csv")
glimpse(dat)
#subset data to remove NA from the y variable
Anxiety_score_without_na <-subset(covid19.survey.data, (!is.na(Anxiety_SCORE)))
glimpse(covid19.survey.data)
set.seed(100)
index = sample(1:nrow(covid19.survey.data), 0.7*nrow(covid19.survey.data))
train = covid19.survey.data[index,] # Create the training data
test = covid19.survey.data[-index,] # Create the test data
dim(train)
dim(test)
View(train)
#Take a glimpse at the data and its structure
glimpse(covid19.survey.data)
#Display all the variable names
names(covid19.survey.data)
cols = c('Age', 'Duration_Corrected', 'Pain', 'Sedentary_Hrs_Per_Day', 'Sedentary_Hrs_Per_Day', 'Walking_wheeling_Hours_Per_Day', 'Walking_wheeling_SCORE',
"Light_sport_Hours_Per_Day", "Light_sport_SCORE",  "Moderate_sport_Hours_Per_Day", "Moderate_sport_SCORE", "Strenous_sport_Hours_Per_Day",
"Strenous_sport_SCORE", "Exercise_Hours_Per_Day", "Exercise_SCORE", "LTPA_SCORE", "Light_housework_Hours_Per_Day","Light_housework_SCORE",
"Heavy_housework_Hours_Per_Day", "Heavy.housework_SCORE", "Home_repairs_Hours_Per_Day", "Home_repairs_SCORE", "Yard_work_Hours_Per_Day",
"Yard_work_SCORE", "Gardening_Hours_Per_Day", "Gardening_SCORE", "Caring_Hours_Per_Day", "Caring_SCORE",  "Household_activity_SCORE","Work_related_activity_Hours_Per_Day",  "Work_related_activity_SCORE",
"PASIDP_SCORE",  "Leaving_the_house_to_work_Hours_Per_Day", "Fear_of_COVID_19_SCORE", "UCLA_Loneliness_SCORE", "SVS_SCORE",
"FSS_SCORE","Global_Fatigue","Anxiety_SCORE",  "Depression_SCORE", "GRSI")
pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))
train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])
pre_proc_val
train[,cols] = predict(pre_proc_val, train[,cols])
# Create list containing the names of independent numeric variables.
cols = c('Age', 'Duration_Corrected', 'Pain', 'Sedentary_Hrs_Per_Day', 'Sedentary_Hrs_Per_Day', 'Walking_wheeling_Hours_Per_Day', 'Walking_wheeling_SCORE',
"Light_sport_Hours_Per_Day", "Light_sport_SCORE",  "Moderate_sport_Hours_Per_Day", "Moderate_sport_SCORE", "Strenous_sport_Hours_Per_Day",
"Strenous_sport_SCORE", "Exercise_Hours_Per_Day", "Exercise_SCORE", "LTPA_SCORE", "Light_housework_Hours_Per_Day","Light_housework_SCORE",
"Heavy_housework_Hours_Per_Day", "Heavy.housework_SCORE", "Home_repairs_Hours_Per_Day", "Home_repairs_SCORE", "Yard_work_Hours_Per_Day",
"Yard_work_SCORE", "Gardening_Hours_Per_Day", "Gardening_SCORE", "Caring_Hours_Per_Day", "Caring_SCORE",  "Household_activity_SCORE","Work_related_activity_Hours_Per_Day",  "Work_related_activity_SCORE",
"PASIDP_SCORE",  "Leaving_the_house_to_work_Hours_Per_Day", "Fear_of_COVID_19_SCORE", "UCLA_Loneliness_SCORE", "SVS_SCORE",
"FSS_SCORE","Global_Fatigue","Anxiety_SCORE",  "Depression_SCORE", "GRSI")
pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))
train[,cols] = predict(pre_proc_val, train[,cols])
# preProcess function from the caret package to complete the scaling task.
# The pre-processing object is fit only to the training data.
pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))
pre_proc_val
train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])
train[,cols]
preProcess(train[,cols], method = c("center", "scale"))
# preProcess function from the caret package to complete the scaling task.
# The pre-processing object is fit only to the training data.
pre_proc_val <- caret::preProcess(train[,cols], method = c("center", "scale"))
#The scaling is applied on both the train and test sets.
train[,cols] = predict(pre_proc_val, train[,cols])
summary(train)
train$Age
class(train$Age)
pre_proc_val
train
cols
# preProcess function from the caret package to complete the scaling task.
# The pre-processing object is fit only to the training data.
pre_proc_val <- caret::preProcess(train[,cols], method = c("center", "scale"))
#The scaling is applied on both the train and test sets.
train[,cols] = predict(pre_proc_val, train[,cols])
View(pre_proc_val)
View(test)
View(train)
# Create list containing the names of independent numeric variables.
cols = c('Age', 'Duration_Corrected', 'Pain', 'Sedentary_Hrs_Per_Day', 'Walking_wheeling_Hours_Per_Day', 'Walking_wheeling_SCORE',
"Light_sport_Hours_Per_Day", "Light_sport_SCORE",  "Moderate_sport_Hours_Per_Day", "Moderate_sport_SCORE", "Strenous_sport_Hours_Per_Day",
"Strenous_sport_SCORE", "Exercise_Hours_Per_Day", "Exercise_SCORE", "LTPA_SCORE", "Light_housework_Hours_Per_Day","Light_housework_SCORE",
"Heavy_housework_Hours_Per_Day", "Heavy.housework_SCORE", "Home_repairs_Hours_Per_Day", "Home_repairs_SCORE", "Yard_work_Hours_Per_Day",
"Yard_work_SCORE", "Gardening_Hours_Per_Day", "Gardening_SCORE", "Caring_Hours_Per_Day", "Caring_SCORE",  "Household_activity_SCORE","Work_related_activity_Hours_Per_Day",  "Work_related_activity_SCORE",
"PASIDP_SCORE",  "Leaving_the_house_to_work_Hours_Per_Day", "Fear_of_COVID_19_SCORE", "UCLA_Loneliness_SCORE", "SVS_SCORE",
"FSS_SCORE","Global_Fatigue","Anxiety_SCORE",  "Depression_SCORE", "GRSI")
# preProcess function from the caret package to complete the scaling task.
# The pre-processing object is fit only to the training data.
pre_proc_val <- caret::preProcess(train[,cols], method = c("center", "scale"))
#The scaling is applied on both the train and test sets.
train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])
summary(train)
lr = lm(unemploy ~ uempmed + psavert + pop + pce, data = train)
summary(lr)
lr = lm(Anxiety_SCORE ~ Age + Pain + Sedentary_Hrs_Per_Day + Walking_wheeling_Hours_Per_Day+Exercise_Hours_Per_Day, data = train)
summary(lr)
eval_metrics = function(model, df, predictions, target){
resids = df[,target] - predictions
resids2 = resids**2
N = length(predictions)
r2 = as.character(round(summary(model)$r.squared, 2))
adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
print(adj_r2) #Adjusted R-squared
print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}
# Step 4.2 - predicting and evaluating the model on train data
predictions = predict(lr, newdata = train)
eval_metrics(lr, train, predictions, target = 'Anxiety_SCORE')
# Step 4.3 - predicting and evaluating the model on test data
predictions = predict(lr, newdata = test)
eval_metrics(lr, test, predictions, target = 'Anxiety_SCORE')
eval_metrics
x = as.matrix(train_dummies)
# Create list containing the names of independent numeric variables.
cols = c('Age', 'Duration_Corrected', 'Sedentary_Hrs_Per_Day', 'Walking_wheeling_Hours_Per_Day', 'Walking_wheeling_SCORE',
"Light_sport_Hours_Per_Day", "Light_sport_SCORE",  "Moderate_sport_Hours_Per_Day", "Moderate_sport_SCORE", "Strenous_sport_Hours_Per_Day",
"Strenous_sport_SCORE", "Exercise_Hours_Per_Day", "Exercise_SCORE", "LTPA_SCORE", "Light_housework_Hours_Per_Day","Light_housework_SCORE",
"Heavy_housework_Hours_Per_Day", "Heavy.housework_SCORE", "Home_repairs_Hours_Per_Day", "Home_repairs_SCORE", "Yard_work_Hours_Per_Day",
"Yard_work_SCORE", "Gardening_Hours_Per_Day", "Gardening_SCORE", "Caring_Hours_Per_Day", "Caring_SCORE",  "Household_activity_SCORE","Work_related_activity_Hours_Per_Day",  "Work_related_activity_SCORE",
"PASIDP_SCORE",  "Leaving_the_house_to_work_Hours_Per_Day", "Fear_of_COVID_19_SCORE", "UCLA_Loneliness_SCORE", "SVS_SCORE",
"FSS_SCORE","Global_Fatigue",  "Depression_SCORE", "GRSI")
lr = lm(Pain ~ Age  + Sedentary_Hrs_Per_Day + Walking_wheeling_Hours_Per_Day+Exercise_Hours_Per_Day, data = train)
summary(lr)
eval_metrics = function(model, df, predictions, target){
resids = df[,target] - predictions
resids2 = resids**2
N = length(predictions)
r2 = as.character(round(summary(model)$r.squared, 2))
adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
print(adj_r2) #Adjusted R-squared
print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}
# Step 4.2 - predicting and evaluating the model on train data
predictions = predict(lr, newdata = train)
eval_metrics(lr, train, predictions, target = 'Anxiety_SCORE')
eval_metrics(lr, train, predictions, target = 'Pain')
# Step 4.2 - predicting and evaluating the model on train data
predictions = predict(lr, newdata = train)
eval_metrics(lr, train, predictions, target = 'Pain')
# Step 4.3 - predicting and evaluating the model on test data --> first numer is R2 and second RMSE
predictions = predict(lr, newdata = test)
eval_metrics(lr, test, predictions, target = 'Pain')
names(train)
##---- 4. Model Evaluation Metrics ----
#Step 4.1 - create the evaluation metrics function
eval_metrics = function(model, df, predictions, target){
resids = df[,target] - predictions
resids2 = resids**2
N = length(predictions)
r2 = as.character(round(summary(model)$r.squared, 2))
adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
print(adj_r2) #Adjusted R-squared
print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}
eval_metrics
# Step 4.2 - predicting and evaluating the model on train data
predictions = predict(lr, newdata = train)
eval_metrics(lr, train, predictions, target = 'Pain')
# Step 4.3 - predicting and evaluating the model on test data --> first numer is R2 and second RMSE
predictions = predict(lr, newdata = test)
eval_metrics(lr, test, predictions, target = 'Pain')
#Display all the variable names
names(covid19.survey.data)
cols = c('Age', 'Duration_Corrected', 'Sedentary_Hrs_Per_Day', 'Walking_wheeling_Hours_Per_Day', 'Walking_wheeling_SCORE',
"Light_sport_Hours_Per_Day", "Light_sport_SCORE",  "Moderate_sport_Hours_Per_Day", "Moderate_sport_SCORE", "Strenous_sport_Hours_Per_Day",
"Strenous_sport_SCORE", "Exercise_Hours_Per_Day", "Exercise_SCORE", "LTPA_SCORE", "Light_housework_Hours_Per_Day","Light_housework_SCORE",
"Heavy_housework_Hours_Per_Day", "Heavy.housework_SCORE", "Home_repairs_Hours_Per_Day", "Home_repairs_SCORE", "Yard_work_Hours_Per_Day",
"Yard_work_SCORE", "Gardening_Hours_Per_Day", "Gardening_SCORE", "Caring_Hours_Per_Day", "Caring_SCORE",
"Work_related_activity_Hours_Per_Day",
"PASIDP_SCORE",  "Leaving_the_house_to_work_Hours_Per_Day", "Fear_of_COVID_19_SCORE", "UCLA_Loneliness_SCORE", "SVS_SCORE",
"FSS_SCORE","Global_Fatigue",  "Depression_SCORE", "GRSI")
lr = lm(Pain ~ Age  + Sedentary_Hrs_Per_Day +Duration_Corrected+ Walking_wheeling_Hours_Per_Day+Exercise_Hours_Per_Day, data = train)
summary(lr)
lr = lm(Anxiety_SCORE ~ Age  + Sedentary_Hrs_Per_Day +Duration_Corrected+ Walking_wheeling_Hours_Per_Day+Exercise_Hours_Per_Day, data = train)
summary(lr)
lr = lm(Work_related_activity_SCORE ~ Age  + Sedentary_Hrs_Per_Day +Duration_Corrected+ Walking_wheeling_Hours_Per_Day+Exercise_Hours_Per_Day, data = train)
summary(lr)
#Display all the variable names
names(covid19.survey.data)
lr = lm(Work_related_activity_SCORE ~ Age +Sex+ Mobility_Aid+ Sedentary_Hrs_Per_Day, data = train)
summary(lr)
lr = lm(Work_related_activity_SCORE ~ Age +Sex+ Mobility_Aid, data = train)
summary(lr)
lr = lm(Work_related_activity_SCORE ~ Age +Sex, data = train)
summary(lr)
lr = lm(Work_related_activity_SCORE ~ Age +Sex, data = test)
summary(lr)
lr = lm(Work_related_activity_SCORE ~ Age +Sex, data = train)
summary(lr)
##---- 4. Model Evaluation Metrics ----
#Step 4.1 - create the evaluation metrics function
eval_metrics = function(model, df, predictions, target){
resids = df[,target] - predictions
resids2 = resids**2
N = length(predictions)
r2 = as.character(round(summary(model)$r.squared, 2))
adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
print(adj_r2) #Adjusted R-squared
print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}
# Step 4.2 - predicting and evaluating the model on train data
predictions = predict(lr, newdata = train)
eval_metrics(lr, train, predictions, target = 'Pain')
# Step 4.3 - predicting and evaluating the model on test data --> first numer is R2 and second RMSE
predictions = predict(lr, newdata = test)
eval_metrics(lr, test, predictions, target = 'Pain')
lr = lm(Work_related_activity_SCORE ~ Age +Sex, data = covid19.survey.data)
summary(lr)
lr = lm(Anxiety_SCORE ~ Age +Sex, data = covid19.survey.data)
summary(lr)
lr = lm(Anxiety_SCORE ~ Age +Sex+Exercise_SCORE, data = covid19.survey.data)
summary(lr)
lr = lm(Anxiety_SCORE ~ Age +Sex*Exercise_SCORE, data = covid19.survey.data)
summary(lr)
lr = lm(Anxiety_SCORE ~ Age +Sex+Exercise_SCORE, data = covid19.survey.data)
summary(lr)
